{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"factoryName": {
			"type": "string",
			"metadata": "Data Factory name",
			"defaultValue": "adfamansimple"
		}
	},
	"variables": {
		"factoryId": "[concat('Microsoft.DataFactory/factories/', parameters('factoryName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('factoryName'), '/Dataflow Demo')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "az_ADLS_ProductsAll",
								"type": "DatasetReference"
							},
							"name": "ProductsAll"
						},
						{
							"dataset": {
								"referenceName": "az_ADLS_ProductModel",
								"type": "DatasetReference"
							},
							"name": "ProductModels"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "az_ADLS_ProductFinal",
								"type": "DatasetReference"
							},
							"name": "ProductsFinal"
						}
					],
					"transformations": [
						{
							"name": "CombineDatasets"
						},
						{
							"name": "RemoveDuplicateColumns"
						},
						{
							"name": "RemoveNoListPrice"
						}
					],
					"scriptLines": [
						"source(output(",
						"          ProductID as short,",
						"          Name as string,",
						"          ProductNumber as integer,",
						"          MakeFlag as boolean,",
						"          FinishedGoodsFlag as boolean,",
						"          Color as string,",
						"          SafetyStockLevel as short,",
						"          ReorderPoint as short,",
						"          StandardCost as double,",
						"          ListPrice as double,",
						"          Size as string,",
						"          SizeUnitMeasureCode as string,",
						"          WeightUnitMeasureCode as string,",
						"          Weight as integer,",
						"          DaysToManufacture as short,",
						"          ProductLine as string,",
						"          Class as string,",
						"          Style as string,",
						"          ProductSubcategoryID as string,",
						"          ProductModelID as string,",
						"          SellStartDate as timestamp,",
						"          SellEndDate as timestamp,",
						"          DiscontinuedDate as timestamp",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> ProductsAll",
						"source(output(",
						"          ProductModelID as string,",
						"          Name as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> ProductModels",
						"ProductsAll, ProductModels lookup(ProductsAll@ProductModelID == ProductModels@ProductModelID,",
						"     multiple: false,",
						"     pickup: 'any',",
						"     broadcast: 'auto')~> CombineDatasets",
						"CombineDatasets select(mapColumn(",
						"          ProductID,",
						"          Name = ProductsAll@Name,",
						"          {Model Name} = ProductModels@Name,",
						"          ProductNumber,",
						"          MakeFlag,",
						"          FinishedGoodsFlag,",
						"          Color,",
						"          SafetyStockLevel,",
						"          ReorderPoint,",
						"          StandardCost,",
						"          ListPrice,",
						"          Size,",
						"          SizeUnitMeasureCode,",
						"          WeightUnitMeasureCode,",
						"          Weight,",
						"          DaysToManufacture,",
						"          ProductLine,",
						"          Class,",
						"          Style,",
						"          ProductSubcategoryID,",
						"          ProductModelID = ProductsAll@ProductModelID,",
						"          SellStartDate,",
						"          SellEndDate,",
						"          DiscontinuedDate",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> RemoveDuplicateColumns",
						"RemoveDuplicateColumns filter(notEquals(ListPrice,0)) ~> RemoveNoListPrice",
						"RemoveNoListPrice sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          ID as string,",
						"          Fname as string,",
						"          Lname as string",
						"     ),",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> ProductsFinal"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow_4_TransformMovies')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "MoviesDB",
								"type": "DatasetReference"
							},
							"name": "MoviesDB"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "MovieRatingWithYear",
								"type": "DatasetReference"
							},
							"name": "DestinationFolder"
						}
					],
					"transformations": [
						{
							"name": "FilterYears"
						},
						{
							"name": "AggregateComedyRatings"
						}
					],
					"scriptLines": [
						"source(output(",
						"          movie as string,",
						"          title as string,",
						"          genres as string,",
						"          year as string,",
						"          Rating as string,",
						"          RottenTomato as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> MoviesDB",
						"MoviesDB filter(toInteger(year) >=1910 && toInteger(year) <= 2000 && rlike(genres,'Comedy')) ~> FilterYears",
						"FilterYears aggregate(groupBy(year = toInteger(year)),",
						"     AverageComedyRating = avg(toInteger(Rating))) ~> AggregateComedyRatings",
						"AggregateComedyRatings sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     filePattern:(concat('Result', toString(currentTimestamp(),'yyyy-MMdd-HH:mm:ss'),'-[n].csv')),",
						"     truncate: true,",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> DestinationFolder"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow_4_filterandsort')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "az_SQLDB_dbo_greentaxi",
								"type": "DatasetReference"
							},
							"name": "sourceassqldb"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "az_sql_ADLS_data_movement",
								"type": "DatasetReference"
							},
							"name": "destinationadls"
						}
					],
					"transformations": [
						{
							"name": "filterTripDay4"
						},
						{
							"name": "sortbyTripDistance"
						}
					],
					"scriptLines": [
						"source(output(",
						"          VendorID as integer,",
						"          PassengerCount as integer,",
						"          TripDistance as float,",
						"          PickupTime as timestamp,",
						"          DropTime as timestamp,",
						"          PickupLocationId as string,",
						"          DropLocationId as string,",
						"          TotalAmount as float,",
						"          PaymentType as string,",
						"          TripYear as integer,",
						"          TripMonth as integer,",
						"          TripDay as integer,",
						"          TripTimeInMinutes as double,",
						"          TripType as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table',",
						"     partitionBy('hash', 1)) ~> sourceassqldb",
						"sourceassqldb filter(TripDistance>=9.73 && TripDay==4,",
						"     partitionBy('hash', 1)) ~> filterTripDay4",
						"filterTripDay4 sort(asc(TripDistance, true),",
						"     caseInsensitive: true,",
						"     partitionBy('hash', 1)) ~> sortbyTripDistance",
						"sortbyTripDistance sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> destinationadls"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow_4_incremental_data_loading')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "AzureSqlTable2",
								"type": "DatasetReference"
							},
							"name": "SqlTablePerson"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Incremental_dataset",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [],
					"scriptLines": [
						"source(output(",
						"          PersonID as integer,",
						"          FirstName as string,",
						"          MiddleName as string,",
						"          LastName as string,",
						"          data_date as date",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     enableCdc: true,",
						"     mode: 'read',",
						"     skipInitialLoad: false,",
						"     waterMarkColumn: 'data_date',",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> SqlTablePerson",
						"SqlTablePerson sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow_4_union')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "emp_US",
								"type": "DatasetReference"
							},
							"name": "empUS"
						},
						{
							"dataset": {
								"referenceName": "emp_IND",
								"type": "DatasetReference"
							},
							"name": "empIND"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "highsalary",
								"type": "DatasetReference"
							},
							"name": "sink1"
						},
						{
							"dataset": {
								"referenceName": "lowsalary",
								"type": "DatasetReference"
							},
							"name": "sink2"
						}
					],
					"transformations": [
						{
							"name": "union1"
						},
						{
							"name": "aggregate1"
						},
						{
							"name": "join1"
						},
						{
							"name": "split1"
						},
						{
							"name": "select1"
						},
						{
							"name": "select2"
						},
						{
							"name": "select3"
						}
					],
					"scriptLines": [
						"source(output(",
						"          ID as integer,",
						"          name as string,",
						"          salary as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table',",
						"     partitionBy('hash', 1)) ~> empUS",
						"source(output(",
						"          ID as integer,",
						"          name as string,",
						"          salary as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> empIND",
						"empUS, empIND union(byName: true,",
						"     partitionBy('hash', 1))~> union1",
						"union1 aggregate(salary = avg(salary),",
						"     partitionBy('hash', 1)) ~> aggregate1",
						"union1, aggregate1 join(union1@salary == aggregate1@salary,",
						"     joinType:'outer',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join1",
						"select1 split(salary>62400,",
						"     disjoint: false) ~> split1@(high, low)",
						"join1 select(mapColumn(",
						"          ID,",
						"          name,",
						"          salary = union1@salary,",
						"          salaryprime = aggregate1@salary",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"split1@high select(mapColumn(",
						"          ID,",
						"          name,",
						"          salary",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select2",
						"split1@low select(mapColumn(",
						"          ID,",
						"          name,",
						"          salary",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select3",
						"select2 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          Column_1 as string,",
						"          Column_2 as string,",
						"          Column_3 as string,",
						"          Column_4 as string,",
						"          Column_5 as string,",
						"          Column_6 as string",
						"     ),",
						"     filePattern:'highsalaryemp.csv',",
						"     truncate: true,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1",
						"select3 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          ProductKey as string,",
						"          OrderDateKey as string,",
						"          DueDateKey as string,",
						"          ShipDateKey as string,",
						"          CustomerKey as string,",
						"          PromotionKey as string,",
						"          CurrencyKey as string,",
						"          SalesTerritoryKey as string,",
						"          SalesOrderNumber as string,",
						"          SalesOrderLineNumber as string,",
						"          RevisionNumber as string,",
						"          OrderQuantity as string,",
						"          UnitPrice as string,",
						"          ExtendedAmount as string,",
						"          UnitPriceDiscountPct as string,",
						"          DiscountAmount as string,",
						"          ProductStandardCost as string,",
						"          TotalProductCost as string,",
						"          SalesAmount as string,",
						"          TaxAmt as string,",
						"          Freight as string,",
						"          CarrierTrackingNumber as string,",
						"          CustomerPONumber as string,",
						"          OrderDate as string,",
						"          DueDate as string,",
						"          ShipDate as string",
						"     ),",
						"     filePattern:'lowsalaryemp.csv',",
						"     truncate: true,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink2"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow_for_join')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "az_sql_dbo_employee",
								"type": "DatasetReference"
							},
							"name": "employee"
						},
						{
							"dataset": {
								"referenceName": "az_sql_dbo_department",
								"type": "DatasetReference"
							},
							"name": "department"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "DelimitedText1",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "join1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          ID as integer,",
						"          name as string,",
						"          salary as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> employee",
						"source(output(",
						"          dept_id as integer,",
						"          post as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> department",
						"employee, department join(ID == dept_id,",
						"     joinType:'inner',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join1",
						"join1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          VendorID as string,",
						"          PassengerCount as string,",
						"          TripDistance as string,",
						"          PickupTime as string,",
						"          DropTime as string,",
						"          PickupLocationId as string,",
						"          DropLocationId as string,",
						"          TotalAmount as string,",
						"          PaymentType as string,",
						"          TripYear as string,",
						"          TripMonth as string,",
						"          TripDay as string,",
						"          TripTimeInMinutes as string,",
						"          TripType as string",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow_lowandhighsalary')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "emp_US",
								"type": "DatasetReference"
							},
							"name": "empus"
						},
						{
							"dataset": {
								"referenceName": "emp_IND",
								"type": "DatasetReference"
							},
							"name": "empind"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "highsalary",
								"type": "DatasetReference"
							},
							"name": "sink1highsalry"
						},
						{
							"dataset": {
								"referenceName": "lowsalary",
								"type": "DatasetReference"
							},
							"name": "sink2lowsalary"
						}
					],
					"transformations": [
						{
							"name": "union1"
						},
						{
							"name": "window1"
						},
						{
							"name": "derivedColumn1"
						},
						{
							"name": "split1"
						},
						{
							"name": "highsalaryemp"
						},
						{
							"name": "lowsalary"
						},
						{
							"name": "sort1"
						},
						{
							"name": "sort2"
						}
					],
					"scriptLines": [
						"source(output(",
						"          ID as integer,",
						"          name as string,",
						"          salary as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table',",
						"     partitionBy('hash', 1)) ~> empus",
						"source(output(",
						"          ID as integer,",
						"          name as string,",
						"          salary as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table',",
						"     partitionBy('hash', 1)) ~> empind",
						"empus, empind union(byName: true)~> union1",
						"union1 window(avg_salary = avg(salary)) ~> window1",
						"window1 derive(Category = iif(salary > avg_salary, 'highsalary', 'lowsalary')) ~> derivedColumn1",
						"derivedColumn1 split(Category=='highsalary',",
						"     disjoint: false) ~> split1@(highsalary, lowsalary)",
						"split1@highsalary select(mapColumn(",
						"          ID,",
						"          name,",
						"          salary",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> highsalaryemp",
						"split1@lowsalary select(mapColumn(",
						"          ID,",
						"          name,",
						"          salary",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> lowsalary",
						"highsalaryemp sort(desc(salary, true)) ~> sort1",
						"lowsalary sort(asc(salary, true)) ~> sort2",
						"sort1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          Column_1 as string,",
						"          Column_2 as string,",
						"          Column_3 as string,",
						"          Column_4 as string,",
						"          Column_5 as string,",
						"          Column_6 as string",
						"     ),",
						"     filePattern:'highsalary.csv',",
						"     truncate: true,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1highsalry",
						"sort2 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          ProductKey as string,",
						"          OrderDateKey as string,",
						"          DueDateKey as string,",
						"          ShipDateKey as string,",
						"          CustomerKey as string,",
						"          PromotionKey as string,",
						"          CurrencyKey as string,",
						"          SalesTerritoryKey as string,",
						"          SalesOrderNumber as string,",
						"          SalesOrderLineNumber as string,",
						"          RevisionNumber as string,",
						"          OrderQuantity as string,",
						"          UnitPrice as string,",
						"          ExtendedAmount as string,",
						"          UnitPriceDiscountPct as string,",
						"          DiscountAmount as string,",
						"          ProductStandardCost as string,",
						"          TotalProductCost as string,",
						"          SalesAmount as string,",
						"          TaxAmt as string,",
						"          Freight as string,",
						"          CarrierTrackingNumber as string,",
						"          CustomerPONumber as string,",
						"          OrderDate as string,",
						"          DueDate as string,",
						"          ShipDate as string",
						"     ),",
						"     filePattern:'lowsalary.csv',",
						"     truncate: true,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink2lowsalary"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Demo 10-pipeline4joindataflow')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Data flow1",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "dataflow_for_join",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"employee": {},
									"department": {},
									"sink1": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"folder": {
					"name": "Demo Pipeline"
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/dataflow_for_join')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/Demo 11-pipeline4uniondataflow4highandlowsalary')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Data flow1",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "dataflow_4_union",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"empUS": {},
									"empIND": {},
									"sink1": {},
									"sink2": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"folder": {
					"name": "Demo Pipeline"
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/dataflow_4_union')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/Demo 12-highandlowsalary')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Data flow1",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "dataflow_lowandhighsalary",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"empus": {},
									"empind": {},
									"sink1highsalry": {},
									"sink2lowsalary": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"folder": {
					"name": "Demo Pipeline"
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/dataflow_lowandhighsalary')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/Demo 16- Incremental Loading SQL to Blob')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "dataflow_4_incremental_data_loading",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "dataflow_4_incremental_data_loading",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"SqlTablePerson": {},
									"sink1": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine",
							"continuationSettings": {
								"customizedCheckpointKey": "523946a6-5062-4579-8b60-bc74b9dc2474"
							}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"folder": {
					"name": "Demo Pipeline"
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/dataflow_4_incremental_data_loading')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/Demo 6-Execute DataFlow')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Run DataFlow Demo-6",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "Dataflow Demo",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"ProductsAll": {},
									"ProductModels": {},
									"ProductsFinal": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"folder": {
					"name": "Demo Pipeline"
				},
				"annotations": [],
				"lastPublishTime": "2023-05-16T10:29:47Z"
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/Dataflow Demo')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/Demo 7-TransformMovies')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "TransformMovies",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "dataflow_4_TransformMovies",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"MoviesDB": {},
									"DestinationFolder": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"folder": {
					"name": "Demo Pipeline"
				},
				"annotations": [],
				"lastPublishTime": "2023-05-17T04:53:51Z"
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/dataflow_4_TransformMovies')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/Demo 9- pipeline_4_dataflow_filterandsort')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Data flow pipeline",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "dataflow_4_filterandsort",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"sourceassqldb": {},
									"destinationadls": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"folder": {
					"name": "Demo Pipeline"
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/dataflow_4_filterandsort')]"
			]
		}
	]
}